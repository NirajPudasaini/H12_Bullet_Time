--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/
	outputs/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
index fcd98a5..fcef5e4 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
@@ -64,7 +64,9 @@ H12_CFG_HANDLESS = ArticulationCfg(
         replace_cylinders_with_capsules=True,
 
        # asset_path= "/home/niraj/isaac_projects/H12_Bullet_Time/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/gentact_descriptions/robots/h1-2/h1_2_handless.urdf",
-        asset_path= "/home/niraj/isaac_projects/H12_Bullet_Time/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/gentact_descriptions/robots/h1-2/h1_2_torso_skin.urdf",
+       
+        #laptop path
+        asset_path= "/home/niraj/gentact_descriptions/robots/h1-2/h1_2_torso_skin.urdf",
 
         activate_contact_sensors=True,
 
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg.py
index ef7cd34..db111a4 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg.py
@@ -147,10 +147,10 @@ class ObservationsCfg:
 class RewardsCfg:
     """Reward terms for the MDP."""
 
-    # Minimal reward: maintain base height at 1.04 m
+    # Penalty for base height deviation (negative weight converts penalty to reward)
     base_height = RewTerm(
         func=mdp.base_height_l2,
-        weight= 0.5,
+        weight=-2.0, 
         params={"asset_cfg": SceneEntityCfg("robot"), "target_height": 1.04},
     )
 
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
index 736c0e1..8e48d27 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
@@ -13,9 +13,13 @@ from isaaclab.managers import SceneEntityCfg
 from isaaclab.envs import ManagerBasedRLEnv
 
 def base_height_l2(env: ManagerBasedRLEnv, target_height: float, asset_cfg: SceneEntityCfg) -> torch.Tensor:
-    """Reward for maintaining base height close to target (default 1.0 m).
+    """Penalize asset height deviation from target using L2 squared kernel.
     
-    Returns negative L2 distance from target height so higher is better.
+    This matches the official Isaac Lab behavior: penalizes when height deviates from target.
+    Returns penalty (negative values) that get worse as height deviates.
+    
+    Note: In RewardsCfg, use negative weight to convert penalty to reward.
+    Example: weight=-1.0 turns -0.01 penalty into +0.01 reward
     """
     # extract robot asset
     asset: Articulation = env.scene[asset_cfg.name]
@@ -23,7 +27,7 @@ def base_height_l2(env: ManagerBasedRLEnv, target_height: float, asset_cfg: Scen
     base_height = asset.data.body_pos_w[:, 0, 2]
     # compute L2 distance from target
     height_error = base_height - target_height
-    # return negative squared error (so reward decreases as height deviates)
+    # return negative squared error (matches official Isaac Lab behavior)
     return -torch.square(height_error)
 
 
@@ -76,20 +80,7 @@ def projectile_hit_penalty(
     penalty: float = -10.0,
     threshold: float = 0.5,
 ) -> torch.Tensor:
-    """Penalty when projectile gets too close to any robot body part.
-    
-    Simple version: if projectile within threshold distance of any robot body â†’ apply penalty.
-    
-    Args:
-        env: The environment
-        asset_cfg: Robot asset config
-        projectile_name: Name of projectile object
-        penalty: Penalty value (typically negative)
-        threshold: Distance threshold in meters
-        
-    Returns:
-        Tensor of rewards (0 or penalty value per env)
-    """
+
     # Get robot
     robot: Articulation = env.scene[asset_cfg.name]
     robot_body_positions = robot.data.body_pos_w  # shape: (num_envs, num_bodies, 3)
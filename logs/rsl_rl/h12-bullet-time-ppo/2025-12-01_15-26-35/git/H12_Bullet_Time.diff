--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   h12_bullet_time/scripts/test_scripts/tof_sensor_readings.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/__init__.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum_phase.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/events.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	h12_bullet_time/source/h12_bullet_time/h12_bullet_time/sensors/
	h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_tof.py
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-01_15-25-17/
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-01_15-26-35/
	outputs/2025-12-01/

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/h12_bullet_time/scripts/test_scripts/tof_sensor_readings.py b/h12_bullet_time/scripts/test_scripts/tof_sensor_readings.py
index c42274e..e69de29 100644
--- a/h12_bullet_time/scripts/test_scripts/tof_sensor_readings.py
+++ b/h12_bullet_time/scripts/test_scripts/tof_sensor_readings.py
@@ -1,177 +0,0 @@
-"""
-TOF Sensor Readings Script
-Loads the H12 URDF and extracts TOF (Time-of-Flight) sensor link information.
-
-Note: Sensor links are defined in the URDF but get merged during USD conversion
-because they have no mass/inertia. We extract their transforms directly from URDF.
-"""
-
-import torch
-import numpy as np
-from pathlib import Path
-import xml.etree.ElementTree as ET
-
-# URDF path
-urdf_path = Path(__file__).parent.parent.parent / "source" / "h12_bullet_time" / "h12_bullet_time" / "assets" / "robots" / "gentact_descriptions" / "robots" / "h1-2" / "h1_2_torso_skin.urdf"
-
-print(f"Loading URDF from: {urdf_path}")
-print(f"URDF exists: {urdf_path.exists()}")
-
-# Parse URDF directly to extract sensor link definitions
-tree = ET.parse(str(urdf_path))
-root = tree.getroot()
-
-# Extract all links
-all_links = {}
-for link in root.findall('.//link'):
-    link_name = link.get('name')
-    all_links[link_name] = link
-
-# Extract all joints and their transforms
-joint_transforms = {}
-for joint in root.findall('.//joint'):
-    joint_name = joint.get('name')
-    joint_type = joint.get('type')
-    child_link = joint.find('child').get('link')
-    parent_link = joint.find('parent').get('link')
-    origin = joint.find('origin')
-    
-    if origin is not None:
-        pos = origin.get('xyz', '0 0 0').split()
-        pos = np.array([float(x) for x in pos])
-        rpy = origin.get('rpy', '0 0 0').split()
-        rpy = np.array([float(x) for x in rpy])
-        
-        joint_transforms[child_link] = {
-            'parent': parent_link,
-            'position': pos,
-            'rpy': rpy,
-            'joint_type': joint_type
-        }
-
-# Now launch Isaac Sim for visualization
-from isaaclab.app import AppLauncher
-
-app_launcher = AppLauncher(headless=False)
-app = app_launcher.app
-
-# Import after Isaac Sim is launched
-import isaaclab.sim as sim_utils
-from isaaclab.assets import Articulation, ArticulationCfg
-from isaaclab.sim import SimulationContext
-from h12_bullet_time.assets.robots.unitree import H12_CFG_HANDLESS
-
-# Setup simulation
-sim_cfg = sim_utils.SimulationCfg(dt=0.01, render_interval=1)
-sim = SimulationContext(sim_cfg)
-sim.set_camera_view([2.0, 0.0, 1.5], [0.0, 0.0, 0.5])
-
-# Create and spawn the robot in simulation
-robot_cfg = H12_CFG_HANDLESS.replace(prim_path="/World/Robot")
-robot = Articulation(cfg=robot_cfg)
-
-# Reset simulation to initialize the robot
-sim.reset()
-
-# Simulation loop
-print("\n" + "="*80)
-print("TOF SENSOR LINKS IN H12 ROBOT (from URDF)")
-print("="*80)
-
-# Filter sensor links from URDF
-sensor_links_urdf = {name: link for name, link in all_links.items() if 'sensor' in name.lower()}
-print(f"\nTotal sensor links in URDF: {len(sensor_links_urdf)}\n")
-
-# Group sensors by parent
-sensor_groups = {}
-for sensor_name in sensor_links_urdf.keys():
-    if sensor_name in joint_transforms:
-        parent = joint_transforms[sensor_name]['parent']
-    else:
-        parent = "unknown"
-    
-    if parent not in sensor_groups:
-        sensor_groups[parent] = []
-    sensor_groups[parent].append(sensor_name)
-
-# Print organized sensor structure from URDF
-print("Sensor Links (organized by parent in URDF):\n")
-for parent_name in sorted(sensor_groups.keys()):
-    sensors = sensor_groups[parent_name]
-    print(f"  {parent_name}: ({len(sensors)} sensors)")
-    for sensor in sorted(sensors)[:5]:
-        print(f"    - {sensor}")
-    if len(sensors) > 5:
-        print(f"    ... and {len(sensors) - 5} more")
-
-print("\n" + "="*80)
-print("SENSOR POSITIONS FROM URDF TRANSFORMS")
-print("="*80 + "\n")
-
-# Simulate and visualize
-for step in range(20):
-    sim.step()
-    
-    if step == 10:  # Print positions after a few steps
-        print("Sensor Link Transform Data (from URDF):\n")
-        
-        print(f"{'Sensor Name':<40} {'Parent Link':<30} {'Position (XYZ)':>25}")
-        print("-" * 100)
-        
-        # Print by parent group
-        for parent_name in sorted(sensor_groups.keys()):
-            sensors = sorted(sensor_groups[parent_name])
-            print(f"\n{parent_name}:")
-            
-            for sensor_name in sensors[:10]:
-                try:
-                    transform = joint_transforms.get(sensor_name, {})
-                    parent = transform.get('parent', 'unknown')
-                    pos = transform.get('position', np.array([0, 0, 0]))
-                    
-                    print(f"  {sensor_name:<38} {parent:<28} ({pos[0]:6.3f}, {pos[1]:6.3f}, {pos[2]:6.3f})")
-                except Exception as e:
-                    print(f"  {sensor_name:<38} ERROR - {e}")
-            
-            if len(sensors) > 10:
-                print(f"  ... and {len(sensors) - 10} more sensors in {parent_name}")
-
-print("\n" + "="*80)
-print("SENSOR DATA IN SIMULATION (Actual Body Count)")
-print("="*80)
-
-print("\n" + "="*80)
-print("SENSOR DATA IN SIMULATION (Actual Body Count)")
-print("="*80)
-
-# Get simulated body names (after merging)
-body_names = robot.body_names
-print(f"\nTotal bodies in simulation: {len(body_names)}")
-print("(Individual sensor links merged into parent bodies during USD conversion)")
-
-print("\n" + "="*80)
-print("SUMMARY")
-print("="*80)
-print(f"""
-URDF Definition:
-- Total sensor links defined: {len(sensor_links_urdf)}
-- Sensor groups: {len(sensor_groups)}
-
-Simulation State:
-- Total bodies: {len(body_names)}
-- Sensor links in simulation: 0 (merged into parents)
-
-Note:
-Sensor links are defined in the URDF but don't appear as separate bodies in 
-the simulation because they have no mass/inertia/collisions. During USD conversion,
-they are merged into their parent links. However, their original transform data
-is preserved in the URDF and can be used to calculate sensor positions.
-
-For TOF sensor functionality:
-1. Use the URDF joint transforms to get sensor frame locations
-2. Calculate absolute positions by forward kinematics from parent links
-3. Use distance to robot links as approximate depth readings
-4. Or implement raycasting from sensor frames toward obstacles
-""")
-
-print("\nDone!")
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
index fcef5e4..6b4b454 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/unitree.py
@@ -66,7 +66,7 @@ H12_CFG_HANDLESS = ArticulationCfg(
        # asset_path= "/home/niraj/isaac_projects/H12_Bullet_Time/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/assets/robots/gentact_descriptions/robots/h1-2/h1_2_handless.urdf",
        
         #laptop path
-        asset_path= "/home/niraj/gentact_descriptions/robots/h1-2/h1_2_torso_skin.urdf",
+        asset_path= "/home/niraj/isaac_projects/gentact_descriptions/robots/h1-2/h1_2_torso_skin.urdf",
 
         activate_contact_sensors=True,
 
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/__init__.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/__init__.py
index 08e9ab7..1b06b00 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/__init__.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/__init__.py
@@ -64,4 +64,14 @@ gym.register(
         "env_cfg_entry_point": f"{__name__}.h12_bullet_time_env_cfg_minimal:MinimalH12EnvCfg",
         "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:PPORunnerCfg",
     },
+)
+
+gym.register(
+    id="Template-H12-Bullet-Time-TOF",
+    entry_point="isaaclab.envs:ManagerBasedRLEnv",
+    disable_env_checker=True,
+    kwargs={
+        "env_cfg_entry_point": f"{__name__}.h12_bullet_time_env_cfg_tof:H12BulletTimeEnvCfg_TOF",
+        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:PPORunnerCfg",
+    },
 )
\ No newline at end of file
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum.py
index 8be96a1..e69de29 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum.py
@@ -1,329 +0,0 @@
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""
-Curriculum Learning Configuration for H12 Bullet Time
-
-Phase 1 (Steps 0-500K): Stand/Balance only (v0)
-Phase 2 (Steps 500K+): Introduce projectiles + dodging (v1)
-
-This config starts easy and gradually introduces difficulty.
-"""
-
-import math
-
-import isaaclab.sim as sim_utils
-from isaaclab.assets import ArticulationCfg, AssetBaseCfg, RigidObjectCfg
-from isaaclab.envs import ManagerBasedRLEnvCfg
-from isaaclab.managers import CurriculumTermCfg as CurTerm
-from isaaclab.managers import EventTermCfg as EventTerm
-from isaaclab.managers import ObservationGroupCfg as ObsGroup
-from isaaclab.managers import ObservationTermCfg as ObsTerm
-from isaaclab.managers import RewardTermCfg as RewTerm
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.managers import TerminationTermCfg as DoneTerm
-from isaaclab.scene import InteractiveSceneCfg
-from isaaclab.utils import configclass
-
-
-from isaaclab.utils.noise import AdditiveUniformNoiseCfg as Unoise
-
-from isaaclab.envs import mdp 
-from . import mdp as local_mdp
-from h12_bullet_time.assets.robots.unitree import H12_CFG_HANDLESS
-
-@configclass
-class H12BulletTimeSceneCfg_Curriculum(InteractiveSceneCfg):
-    """Configuration for H12 Bullet Time curriculum scene with optional projectiles."""
-
-    # ground plane
-    ground = AssetBaseCfg(
-        prim_path="/World/ground",
-        spawn=sim_utils.GroundPlaneCfg(size=(100.0, 100.0)),
-    )
-
-    # robot - H12 humanoid
-    robot: ArticulationCfg = H12_CFG_HANDLESS.replace(prim_path="{ENV_REGEX_NS}/Robot")
-   
-    # lights
-    dome_light = AssetBaseCfg(
-        prim_path="/World/DomeLight",
-        spawn=sim_utils.DomeLightCfg(color=(0.9, 0.9, 0.9), intensity=500.0),
-    )
-
-    # Projectile (always in scene, but only spawned after curriculum milestone)
-    Projectile = RigidObjectCfg(
-        prim_path="{ENV_REGEX_NS}/Projectile",
-        spawn=sim_utils.SphereCfg(
-            radius=0.075,  
-            visual_material=sim_utils.PreviewSurfaceCfg(
-                diffuse_color=(0.0, 0.0, 0.2),  # Blue
-                metallic=0.2,
-            ),
-            rigid_props=sim_utils.RigidBodyPropertiesCfg(
-                solver_position_iteration_count=4,
-                solver_velocity_iteration_count=0,
-            ),
-            mass_props=sim_utils.MassPropertiesCfg(mass=0.5),
-            collision_props=sim_utils.CollisionPropertiesCfg(collision_enabled=True),
-        ),
-        init_state=RigidObjectCfg.InitialStateCfg(
-            pos=(-1.0, -1.0, 0.0),
-            rot=(1.0, 0.0, 0.0, 0.0),
-            lin_vel=(0.0, 0.0, 0.0),
-            ang_vel=(0.0, 0.0, 0.0),
-        ),
-    )
-
-##
-# MDP settings
-##
-
-@configclass
-class ActionsCfg:
-    """Action specifications for the MDP."""
-
-    joint_effort = mdp.JointPositionActionCfg(
-        asset_name="robot",
-        joint_names=[
-            # Left leg
-            "left_hip_yaw_joint",
-            "left_hip_roll_joint",
-            "left_hip_pitch_joint",
-            "left_knee_joint",        #6      
-            "left_ankle_pitch_joint", #0
-            "left_ankle_roll_joint",  #1
-
-            # Right leg
-            "right_hip_yaw_joint",   #5
-            "right_hip_roll_joint",  #4
-            "right_hip_pitch_joint", #3
-            "right_knee_joint",
-            "right_ankle_pitch_joint",
-            "right_ankle_roll_joint",
-
-            #torso
-            "torso_joint",
-
-            #Left arm
-            "left_shoulder_pitch_joint", #7
-            "left_shoulder_roll_joint",  #8
-            "left_elbow_joint",   #2
-
-            # Right arm
-            "right_shoulder_pitch_joint",   
-            "right_shoulder_roll_joint",   
-            "right_elbow_joint",
-        ],
-        scale= 0.25,  
-    )
-
-
-@configclass
-class ObservationsCfg:
-    """Observation specifications for the MDP."""
-
-    @configclass
-    class PolicyCfg(ObsGroup):
-        """Observations for policy group."""
-
-        base_ang_vel = ObsTerm(func=mdp.base_ang_vel, scale = 0.2, noise=Unoise(n_min=-0.2, n_max=0.2))
-        projected_gravity = ObsTerm(func=mdp.projected_gravity, noise=Unoise(n_min=-0.05, n_max=0.05))
-        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel, noise=Unoise(n_min=-0.2, n_max=0.2))
-        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel, noise=Unoise(n_min=-0.01, n_max=0.01))
-        last_action = ObsTerm(func=mdp.last_action)
-        
-        # Projectile observations (external sensing) - policy needs these to dodge!
-        projectile_pos_rel = ObsTerm(
-            func=local_mdp.projectile_position_relative,
-            scale=0.25,
-        )
-        projectile_vel = ObsTerm(
-            func=local_mdp.projectile_velocity,
-            scale=0.1,
-        )
-        projectile_dist = ObsTerm(
-            func=local_mdp.projectile_distance_obs,
-            scale=0.5,
-        )
-        
-        def __post_init__(self) -> None:
-            self.enable_corruption = True
-            self.concatenate_terms = True
-
-    policy: PolicyCfg = PolicyCfg()
-    
-    @configclass
-    class CriticCfg(ObsGroup):
-        """Observations for critic group - includes privileged base velocity + projectile info (Phase 2)."""
-        
-        base_ang_vel = ObsTerm(func=mdp.base_ang_vel, scale = 0.2, noise=Unoise(n_min=-0.2, n_max=0.2))
-        projected_gravity = ObsTerm(func=mdp.projected_gravity, noise=Unoise(n_min=-0.05, n_max=0.05))
-        joint_pos_rel = ObsTerm(func=mdp.joint_pos_rel, noise=Unoise(n_min=-0.2, n_max=0.2))
-        joint_vel_rel = ObsTerm(func=mdp.joint_vel_rel, noise=Unoise(n_min=-0.01, n_max=0.01))
-        last_action = ObsTerm(func=mdp.last_action)
-        
-        # Privileged info: linear velocity
-        base_lin_vel = ObsTerm(func=mdp.base_lin_vel, scale=0.1)
-        
-        # Projectile observations (Phase 2: added for dodging task)
-        projectile_pos_rel = ObsTerm(
-            func=local_mdp.projectile_position_relative,
-            scale=0.25,
-        )
-        projectile_vel = ObsTerm(
-            func=local_mdp.projectile_velocity,
-            scale=0.1,
-        )
-        projectile_dist = ObsTerm(
-            func=local_mdp.projectile_distance_obs,
-            scale=0.5,
-        )
-        
-        def __post_init__(self) -> None:
-            self.enable_corruption = False
-            self.concatenate_terms = True
-
-    critic: CriticCfg = CriticCfg()
-
-
-@configclass
-class RewardsCfg:
-
-    # Phase 1 rewards (always active): Stand and balance
-    base_height = RewTerm(
-        func=local_mdp.base_height_l2,
-        weight=10.0,
-        params={"asset_cfg": SceneEntityCfg("robot"), "target_height": 1.04},
-    )
-
-    alive_bonus = RewTerm(
-        func=local_mdp.alive_bonus,
-        weight= 5.0,
-        params={},
-    )
-
-    flat_orientation_l2 = RewTerm(func=mdp.flat_orientation_l2, weight=-1.0)
-    joint_acc = RewTerm(func=mdp.joint_acc_l2, weight=-2.5e-7)
-    action_rate = RewTerm(func=mdp.action_rate_l2, weight=-0.005)
-    dof_pos_limits = RewTerm(func=mdp.joint_pos_limits, weight=-3.0)
-
-    # Standing still reward (light)
-    base_velocity_reward = RewTerm(
-        func=local_mdp.base_velocity_reward,
-        weight=10,
-        params={"asset_cfg": SceneEntityCfg("robot"), "scale": 100.0},
-    )
-
-    # Phase 2 reward (controlled by curriculum manager, see CurriculumCfg below)
-    # Starts at weight=0.0 (Phase 1), automatically set to 1.0 at step 500K (Phase 2)
-    projectile_penalty = RewTerm(
-        func=local_mdp.projectile_proximity_penalty,
-        weight=1.0,  # Active from start (no curriculum gating)
-        params={
-            "asset_cfg": SceneEntityCfg("robot"),
-            "projectile_name": "Projectile",
-            "max_distance": 3.0,
-            "penalty_scale": -10.0,  # Strong negative penalty when close
-        },
-    )
-
-
-@configclass
-class EventCfg:
-    """Configuration for events."""
-
-    # Reset base position and velocity
-    reset_base = EventTerm(
-        func=mdp.reset_root_state_uniform,
-        mode="reset",
-        params={
-            "pose_range": {"x": (-0.0, 0.0), "y": (-0.0, 0.0), "yaw": (0.0, 0.0)},
-            "velocity_range": {
-                "x": (0.0, 0.0),
-                "y": (0.0, 0.0),
-                "z": (0.0, 0.0),
-                "roll": (0.0, 0.0),
-                "pitch": (0.0, 0.0),
-                "yaw": (0.0, 0.0),
-            },
-        },
-    )
-
-    # Reset robot joints
-    reset_robot_joints = EventTerm(
-        func=mdp.reset_joints_by_scale,
-        mode="reset",
-        params={
-            "position_range": (1.0, 1.0),
-            "velocity_range": (-1.0, 1.0),
-        },
-    )
-
-    # Always launch projectiles on reset (no curriculum gating)
-    launch_projectile = EventTerm(
-        func=local_mdp.launch_projectile,
-        mode="reset",
-        params={
-            "asset_cfg": SceneEntityCfg("Projectile"),
-        },
-    )
-
-
-@configclass
-class CurriculumCfg:
-    """No curriculum gating: projectile penalty active from start."""
-    pass
-
-
-@configclass
-class TerminationsCfg:
-    """Termination terms for the MDP."""
-
-    # Time out
-    time_out = DoneTerm(func=mdp.time_out, time_out=True)
-
-    # Base height too low (fell down)
-    base_height_low = DoneTerm(
-        func=local_mdp.base_height_below_threshold,
-        params={"asset_cfg": SceneEntityCfg("robot"), "threshold": 0.4},
-    )
-
-    # Projectile hit (phase 2 only, activated at milestone)
-    # NOTE: Disabled hard termination on projectile hit. Use distance-based
-    # rewards (`projectile_penalty`) instead so agent is punished softly
-    # when projectiles approach. If you want to re-enable termination, add a
-    # DoneTerm using `local_mdp.projectile_hit`.
-
-##
-# Environment configuration
-##
-
-
-@configclass
-class H12BulletTimeEnvCfg_Curriculum(ManagerBasedRLEnvCfg):
-    # Scene settings
-    scene: H12BulletTimeSceneCfg_Curriculum = H12BulletTimeSceneCfg_Curriculum(num_envs=4096, env_spacing=4.0)
-    # Basic settings
-    observations: ObservationsCfg = ObservationsCfg()
-    actions: ActionsCfg = ActionsCfg()
-    events: EventCfg = EventCfg()
-    # MDP settings
-    rewards: RewardsCfg = RewardsCfg()
-    terminations: TerminationsCfg = TerminationsCfg()
-    # Curriculum settings
-    curriculum: CurriculumCfg = CurriculumCfg()
-
-    # Post initialization
-    def __post_init__(self) -> None:
-        """Post initialization."""
-        # general settings
-        self.decimation = 2
-        self.episode_length_s = 5  # 5 second episodes (shorter rollouts -> more resets)
-        # viewer settings
-        self.viewer.eye = (8.0, 0.0, 5.0)
-        # simulation settings
-        self.sim.dt = 1 / 120
-        self.sim.render_interval = self.decimation
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum_phase.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum_phase.py
index 9678fe3..35fe099 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum_phase.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/h12_bullet_time_env_cfg_curriculum_phase.py
@@ -338,4 +338,4 @@ class H12BulletTimeEnvCfg_Curriculum_Phase(ManagerBasedRLEnvCfg):
         self.viewer.eye = (8.0, 0.0, 5.0)
         # simulation settings
         self.sim.dt = 1 / 120
-        self.sim.render_interval = self.decimation
+        self.sim.render_interval = self.decimation
\ No newline at end of file
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/events.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/events.py
index 8d15d8f..e5135f0 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/events.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/events.py
@@ -145,4 +145,3 @@ def launch_projectile_curriculum(
 #         except (IndexError, RuntimeError):
 #             # If action tensor shape is different, silently skip
 #             pass
-
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
index 5867b0f..870348e 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
@@ -2,7 +2,8 @@
 from __future__ import annotations
 
 import torch
-from typing import TYPE_CHECKING
+from isaaclab.envs import ManagerBasedRLEnv
+from isaaclab.managers import SceneEntityCfg
 
 # Import the real observation functions from Isaac Lab
 from isaaclab.envs.mdp import (
@@ -13,10 +14,6 @@ from isaaclab.envs.mdp import (
     last_action,
 )
 
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-    from isaaclab.managers import SceneEntityCfg
-
 __all__ = [
     "base_ang_vel",
     "joint_pos_rel",
@@ -26,85 +23,121 @@ __all__ = [
     "projectile_position_relative",
     "projectile_velocity",
     "projectile_distance_obs",
+    "tof_distances_obs",
 ]
 
 
-def projectile_position_relative(
-    env: ManagerBasedRLEnv,
-    projectile_name: str = "Projectile",
-    robot_link_name: str = "head",
-) -> torch.Tensor:
-
-    robot = env.scene["robot"]
-
-    # Determine robot link/world position to use
-    robot_pos = None
-    try:
-        body_names = list(robot.body_names)
-    except Exception:
-        body_names = []
-
-    if robot_link_name is not None and robot_link_name in body_names:
-        idx = body_names.index(robot_link_name)
-        # body_pos_w shape: (num_envs, num_bodies, 3)
-        robot_pos = robot.data.body_pos_w[:, idx, :]
-    else:
-        # Fallback to root_pos_w (num_envs, 3)
-        robot_pos = robot.data.root_pos_w
-
-    try:
-        projectile = env.scene[projectile_name]
-        proj_pos = projectile.data.root_pos_w  # (num_envs, 3)
-    except (KeyError, AttributeError):
-        # If projectile not found, return zeros
-        return torch.zeros((env.num_envs, 3), device=env.device, dtype=torch.float32)
-
-    # Relative position: projectile - robot_link
-    return proj_pos - robot_pos
-
-
-def projectile_velocity(
-    env: ManagerBasedRLEnv,
-    projectile_name: str = "Projectile",
-) -> torch.Tensor:
-    """Get projectile velocity in world frame.
-
-    Returns a (num_envs, 3) tensor. If the projectile is not present returns zeros.
+def projectile_position_relative(env: ManagerBasedRLEnv, projectile_name: str = "Projectile") -> torch.Tensor:
+    """Projectile position relative to base frame.
+    
+    Args:
+        env: Environment instance
+        projectile_name: Name of the projectile entity in the scene
+        
+    Returns:
+        Position of projectile relative to robot base (num_envs, 3)
+    """
+    projectile = env.scene[projectile_name]
+    base = env.scene["robot"]
+    
+    # Get projectile position in world frame
+    projectile_pos_world = projectile.data.root_pos_w  # (num_envs, 3)
+    base_pos_world = base.data.root_pos_w  # (num_envs, 3)
+    
+    # Get relative position
+    pos_rel = projectile_pos_world - base_pos_world
+    
+    return pos_rel
+
+
+def projectile_velocity(env: ManagerBasedRLEnv, projectile_name: str = "Projectile") -> torch.Tensor:
+    """Projectile velocity in world frame.
+    
+    Args:
+        env: Environment instance
+        projectile_name: Name of the projectile entity in the scene
+        
+    Returns:
+        Velocity of projectile (num_envs, 3)
+    """
+    projectile = env.scene[projectile_name]
+    return projectile.data.root_lin_vel_w  # (num_envs, 3)
+
+
+def projectile_distance_obs(env: ManagerBasedRLEnv, projectile_name: str = "Projectile") -> torch.Tensor:
+    """Distance from base to projectile.
+    
+    Args:
+        env: Environment instance
+        projectile_name: Name of the projectile entity in the scene
+        
+    Returns:
+        Distance to projectile (num_envs, 1)
     """
-    try:
-        projectile = env.scene[projectile_name]
-        return projectile.data.root_lin_vel_w  # (num_envs, 3)
-    except (KeyError, AttributeError):
-        # If projectile not found, return zeros
-        return torch.zeros((env.num_envs, 3), device=env.device, dtype=torch.float32)
+    projectile = env.scene[projectile_name]
+    base = env.scene["robot"]
+    
+    projectile_pos = projectile.data.root_pos_w
+    base_pos = base.data.root_pos_w
+    
+    distance = torch.norm(projectile_pos - base_pos, dim=1, keepdim=True)
+    
+    return distance
 
 
-def projectile_distance_obs(
+def tof_distances_obs(
     env: ManagerBasedRLEnv,
-    projectile_name: str = "Projectile",
-    robot_link_name: str = "head",
+    max_range: float = 4.0,
+    handle_nan: str = "replace_with_max",
 ) -> torch.Tensor:
-
-    robot = env.scene["robot"]
-
-    # Choose robot link position
-    try:
-        body_names = list(robot.body_names)
-    except Exception:
-        body_names = []
-
-    if robot_link_name is not None and robot_link_name in body_names:
-        idx = body_names.index(robot_link_name)
-        robot_pos = robot.data.body_pos_w[:, idx, :]
-    else:
-        robot_pos = robot.data.root_pos_w
-
-    try:
-        projectile = env.scene[projectile_name]
-        proj_pos = projectile.data.root_pos_w  # (num_envs, 3)
-    except (KeyError, AttributeError):
-        # If projectile not found, return zeros (no threat)
-        return torch.zeros((env.num_envs, 1), device=env.device, dtype=torch.float32)
-
-    distance = torch.norm(proj_pos - robot_pos, dim=-1, keepdim=True)
-    return distance
+    """TOF sensor distance readings aggregated across all sensors.
+    
+    Args:
+        env: Environment instance
+        max_range: Maximum range of TOF sensors (used for normalization)
+        handle_nan: How to handle NaN values:
+            - "replace_with_max": Replace NaN with max_range
+            - "zero": Replace NaN with 0
+            - "keep": Keep NaN values as-is
+        
+    Returns:
+        Flattened TOF sensor distances (num_envs, total_num_measurements)
+        Normalized by max_range so values are in [0, 1]
+    """
+    # Check if environment has sensors
+    if not hasattr(env.scene, "sensors") or len(env.scene.sensors) == 0:
+        # No sensors in scene, return empty tensor
+        num_envs = env.num_envs
+        return torch.zeros((num_envs, 0), dtype=torch.float32, device=env.device)
+    
+    # Collect distances from all sensors
+    all_distances = []
+    
+    for sensor in env.scene.sensors:
+        # Try to get TOF distance data
+        if hasattr(sensor, "data") and hasattr(sensor.data, "distances"):
+            distances = sensor.data.distances  # Shape: (num_envs, num_frames, num_targets)
+            
+            # Flatten each sensor's measurements
+            distances_flat = distances.reshape(distances.shape[0], -1)  # (num_envs, flattened_dims)
+            all_distances.append(distances_flat)
+    
+    if not all_distances:
+        # No valid sensor data found, return empty tensor
+        num_envs = env.num_envs
+        return torch.zeros((num_envs, 0), dtype=torch.float32, device=env.device)
+    
+    # Concatenate all sensor readings
+    tof_readings = torch.cat(all_distances, dim=1)  # (num_envs, total_dims)
+    
+    # Handle NaN values
+    if handle_nan == "replace_with_max":
+        tof_readings = torch.where(torch.isnan(tof_readings), torch.tensor(max_range, device=env.device), tof_readings)
+    elif handle_nan == "zero":
+        tof_readings = torch.where(torch.isnan(tof_readings), torch.tensor(0.0, device=env.device), tof_readings)
+    # else: keep as-is
+    
+    # Normalize by max_range
+    tof_normalized = tof_readings / max_range
+    
+    return tof_normalized
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
index 1adfd94..7ad82b2 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/rewards.py
@@ -14,7 +14,6 @@ __all__ = [
     "projectile_hit_penalty",
     "projectile_proximity_penalty",
     "projectile_distance",
-    "projectile_contact_penalty",
     "torso_pitch_curriculum",
     "torso_pitch_reward",
 ]
@@ -26,7 +25,6 @@ def alive_bonus(env: ManagerBasedRLEnv) -> torch.Tensor:
     return torch.ones(env.num_envs, dtype=torch.float32, device=env.device)
 
 
-
 def base_height_l2(
     env: ManagerBasedRLEnv,
     asset_cfg: SceneEntityCfg,
@@ -187,7 +185,6 @@ def projectile_proximity_penalty(
         "right_elbow_link",
         "left_shoulder_yaw_link",
         "right_shoulder_yaw_link",
-        # Lidar mounted on torso (protect sensor)
         "lidar_link",
     ]
 
@@ -399,4 +396,3 @@ def torso_pitch_reward(
     reward = float(scale) * (abs_pitch / float(max_pitch))
 
     return reward.to(device=env.device)
-
--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-02_11-38-21/
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-02_11-40-02/
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-02_11-41-14/
	logs/rsl_rl/h12-bullet-time-ppo/2025-12-02_11-43-24/
	outputs/2025-12-02/11-38-21/
	outputs/2025-12-02/11-40-02/
	outputs/2025-12-02/11-41-14/
	outputs/2025-12-02/11-43-24/
	test_tof_obs.py

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
index d052b9e..5ab3fd1 100644
--- a/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
+++ b/h12_bullet_time/source/h12_bullet_time/h12_bullet_time/tasks/manager_based/h12_bullet_time/mdp/observations.py
@@ -99,9 +99,10 @@ def tof_distances_obs(
         env: Environment instance
         max_range: Maximum range of TOF sensors (used for normalization)
         handle_nan: How to handle NaN values:
-            - "replace_with_max": Replace NaN with max_range
-            - "zero": Replace NaN with 0
-            - "keep": Keep NaN values as-is
+            - "replace_with_max": Replace NaN with max_range (projectile out of range)
+            - "zero": Replace NaN with 0 (treat as very close, conservative)
+            - "mean": Replace NaN with normalized mean distance (indicates uncertainty)
+            - "keep": Keep NaN values as-is (for downstream filtering)
         
     Returns:
         Flattened TOF sensor distances (num_envs, total_num_measurements)
@@ -115,6 +116,7 @@ def tof_distances_obs(
     
     # Collect distances from all sensors
     all_distances = []
+    debug = False  # Set to True for troubleshooting
     
     # env.scene.sensors is a list of sensor names (strings)
     for sensor_name in env.scene.sensors:
@@ -125,7 +127,7 @@ def tof_distances_obs(
             
             # Try tof_distances first (preferred, includes FOV-based culling)
             if hasattr(sensor_data, "tof_distances"):
-                distances = sensor_data.tof_distances  # Shape: (num_envs, num_sensors, num_targets)
+                distances = sensor_data.tof_distances  # Shape: (num_envs, num_sensors, num_targets, num_pixels)
             # Fallback to raw_target_distances
             elif hasattr(sensor_data, "raw_target_distances"):
                 distances = sensor_data.raw_target_distances
@@ -134,13 +136,26 @@ def tof_distances_obs(
                 distances = sensor_data.distances
             else:
                 # Skip this sensor if it has no distance data
+                if debug:
+                    print(f"[TOF OBS] {sensor_name}: no distance attributes found")
                 continue
             
-            # Flatten each sensor's measurements: (num_envs, num_sensors, num_targets) -> (num_envs, flattened)
-            distances_flat = distances.reshape(distances.shape[0], -1)  # (num_envs, flattened_dims)
+            if debug:
+                print(f"[TOF OBS] {sensor_name}: distances shape = {distances.shape}")
+            
+            # Flatten each sensor's measurement points and targets into a single feature vector
+            # Shape: (num_envs, num_sensors, num_targets, num_pixels) -> (num_envs, num_sensors * num_targets * num_pixels)
+            num_envs = distances.shape[0]
+            num_measurement_points = distances.shape[1]
+            # Reshape: (num_envs, num_measurement_points, num_targets, num_pixels) -> (num_envs, num_measurement_points * num_targets * num_pixels)
+            distances_flat = distances.reshape(num_envs, num_measurement_points * distances.shape[2] * distances.shape[3])
             all_distances.append(distances_flat)
-        except Exception:
+            if debug:
+                print(f"[TOF OBS] {sensor_name}: flattened shape = {distances_flat.shape}")
+        except Exception as e:
             # Skip sensors that fail to access data
+            if debug:
+                print(f"[TOF OBS] {sensor_name}: ERROR: {e}")
             continue
     
     if not all_distances:
@@ -148,17 +163,35 @@ def tof_distances_obs(
         num_envs = env.num_envs
         return torch.zeros((num_envs, 0), dtype=torch.float32, device=env.device)
     
-    # Concatenate all sensor readings
-    tof_readings = torch.cat(all_distances, dim=1)  # (num_envs, total_dims)
+    # Concatenate all sensor readings (stack features from all sensors)
+    # Each sensor has shape (num_envs, flattened_sensor_features)
+    tof_readings = torch.cat(all_distances, dim=1)  # (num_envs, total_features_all_sensors)
     
-    # Handle NaN values
+    # Handle NaN values before normalization
     if handle_nan == "replace_with_max":
-        tof_readings = torch.where(torch.isnan(tof_readings), torch.tensor(max_range, device=env.device), tof_readings)
+        # Out of range = max_range (most conservative, projectile is far)
+        tof_readings = torch.nan_to_num(tof_readings, nan=max_range)
     elif handle_nan == "zero":
-        tof_readings = torch.where(torch.isnan(tof_readings), torch.tensor(0.0, device=env.device), tof_readings)
-    # else: keep as-is
+        # Not detected = 0 (most conservative, treat as very close threat)
+        tof_readings = torch.nan_to_num(tof_readings, nan=0.0)
+    elif handle_nan == "mean":
+        # Not detected = mean of valid detections (indicates uncertainty)
+        # Compute mean for each environment (ignoring NaN)
+        valid_mask = ~torch.isnan(tof_readings)
+        for env_idx in range(tof_readings.shape[0]):
+            valid_distances = tof_readings[env_idx, valid_mask[env_idx]]
+            if valid_distances.numel() > 0:
+                mean_dist = valid_distances.mean()
+            else:
+                # No valid detections in this env, use max_range
+                mean_dist = max_range
+            tof_readings[env_idx, ~valid_mask[env_idx]] = mean_dist
+    # else: keep as-is (NaN remains)
     
     # Normalize by max_range
     tof_normalized = tof_readings / max_range
     
+    # Clamp to [0, 1] range in case of any edge cases
+    tof_normalized = torch.clamp(tof_normalized, min=0.0, max=1.0)
+    
     return tof_normalized